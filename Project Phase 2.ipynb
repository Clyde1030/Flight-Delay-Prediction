{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e1518f9-68de-4525-b826-92a752504c31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Flight Predict - Predicting Departure Delays using ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c750e867-1ab7-4860-bb45-99001fdba91e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## Phase leader plan in Table format\n",
    "| Phase | Leader           | Duration | Project Plan |\n",
    "|------:|----------------  |:--------:|--------------------------------------------------------------------------------------|\n",
    "| 1     |Kowsalya Ganesan  | Oct 27- Nov 2  |Abstract, Data description, Machine algorithms and metrics, Machine Learning Pipelines |\n",
    "| 2     |   Eric Wu, Steven Au               |   Nov 3 - Nov 19             | Abstract, Data description, Feature Engineering, EDA, Lasso, Model implementation, Hyper parameter tuning, Next steps |\n",
    "| 3     |   Yu-Sheng, Naresh               |    Nov 20 - Dec 10            | TBD |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c84ec2ee-bc84-48a8-bb14-03074f32a1d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Credit assignment plan / who does/did what\n",
    "| Team Member (A–Z by first name)| Responsibilities     | Time Spent |\n",
    "|--------------------------------|----------------------|------------|\n",
    "| Eric Wu                        |Logistic Regression, Feature Engineering, Hyper-parameter search, Reports                     |24 hours            |\n",
    "| Kowsalya Ganesan               | Data Analysis, Data Quality Check, Data Imputation Strategy, Data Quality Fixes, Including External Data, Feature Engineering                      |      32  hours    |\n",
    "| Naresh Kumar                   |  Problem definition, Abstract preparation, Feature analysis, Lasso regularization,  Pipeline Analysis, Data Quality Fixes,  Conclusion                    | 26 hours           |\n",
    "| Steven Au                      |  XGBoost and Random Forest models, Feature Engineering for models, Cross Validation, Hyperparameter tuning, Model Performance Report on XG/RF                  |   24 hours     |\n",
    "| Yu-Sheng Lee                   | EDA (Distribution of Target Variables, Correlation Analysis, Time Series Decomposition, PCA), Experiment on XGBoost Model| 26 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2a9e383-7e4b-4a29-b623-a99c445e73c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Team Members\n",
    "| Name (A–Z by first name) | Email     | photo      |\n",
    "|--------------------|----------------------|-------------|\n",
    "| Eric Wu          |enqiwu@berkeley.edu| <img src=\"https://raw.githubusercontent.com/ericwu2024/w261/00189ab0be487ac67b350983d8b23f0e1c98f7e2/eric_wu.jpg\" width=\"120\" height=\"120\">|\n",
    "| Kowsalya Ganesan |kowsalya@berkeley.edu|<img src=\"https://raw.githubusercontent.com/ericwu2024/w261/00189ab0be487ac67b350983d8b23f0e1c98f7e2/kowsalya_ganesan.jpeg\" width=\"120\" height=\"120\">|\n",
    "| Naresh Kumar     |naresh_kumar@berkeley.edu|<img src=\"https://raw.githubusercontent.com/ericwu2024/w261/00189ab0be487ac67b350983d8b23f0e1c98f7e2/naresh_kumar.png\" width=\"120\" height=\"120\">|\n",
    "| Steven Au        |steau@berkeley.edu|<img src=\"https://raw.githubusercontent.com/ericwu2024/w261/00189ab0be487ac67b350983d8b23f0e1c98f7e2/steven_au.jpeg\" width=\"120\" height=\"120\">|\n",
    "| Yu-Sheng Lee     |yushenglee@berkeley.edu|<img src=\"https://raw.githubusercontent.com/ericwu2024/w261/00189ab0be487ac67b350983d8b23f0e1c98f7e2/yusheng_lee.jpg\" width=\"120\" height=\"120\">|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da0bba43-ca5c-42f3-9bc6-32e5cf3432c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Abstract\n",
    "Airports face significant operational challenges due to unpredictable flight delays, costing the U.S. economy an estimated $30–$35 billion annually. We address this with a data-driven model that predicts whether a departing flight will be delayed (DEP_DELAY_GROUP ≥ 1) or on-time (≤ 0) prior to its scheduled departure, helping airport teams optimize staffing, manage congestion, and improve passenger experience.\n",
    "\n",
    "Using a flight operations dataset enriched with weather, traffic, peak-hour, and calendar features on the test data, \n",
    "- We establish a **logistic regression** baseline, yielding **0.27 precision, 0.34 recall, and 0.30 F1 score,** respectively, for the delayed class. This reflects the challenge of class imbalance (18% delayed). Key predictors include weather and peak-hour status. \n",
    "- **Ensemble methods** further improved these metrics with **Random Forest** producing scores of **0.78 precision, 0.70 recall, and 0.74 F1,** and **XGBoost** with **0.78 precision, 0.74 recall, and 0.76 F1,** showing better minority-class detection.\n",
    "\n",
    "Next steps include engineering additional network-based features, rebalancing strategies, scaling to five years of data, and implementing advanced neural network models to further improve the F1 score and provide actionable insights for airport operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17190f0b-c66a-46ea-901c-aa1563024fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bffb95f7-5523-4051-8356-b44484f357b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Overview\n",
    "\n",
    "Flight delays pose significant operational challenges for airlines, airports, and passengers. This project aims to predict whether a U.S. domestic commercial flight will depart late (based on operational delay thresholds) by leveraging:\n",
    "\n",
    "- Flight operational records\n",
    "- Hourly weather observations\n",
    "- Airport metadata\n",
    "\n",
    "We systematically analyzed and cleaned the dataset, engineered relevant predictive features, and built a machine learning classification model to predict the delay status of upcoming departures - results that will help stakeholders improve resource planning and passenger experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "902aa4ba-8401-448b-a1e4-f02d7588cb5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Description\n",
    "\n",
    "| Dataset                                    | Source                                                   | Description                                                                      |\n",
    "| ------------------------------------------ | -------------------------------------------------------- | -------------------------------------------------------------------------------- |\n",
    "| **On-Time Performance Flight Data (OTPW)** | [U.S. DOT Bureau of Transportation Statistics]((https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ) | Detailed flight-level operational data (times, delays, identifiers)              |\n",
    "| **Hourly Weather Data**                    | [NOAA / Databricks-provided weather tables](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00679)               | Temperature, wind, visibility, precipitation, humidity, and other hourly metrics |\n",
    "| **Airport Reference Data**                 | [Airport Metadata](https://datahub.io/core/airport-codes)                                    | Latitude, longitude, elevation, airport type, region                             |\n",
    "|**External Data**                  |                US Holiday, Seasonal Pattern      |     +- 3 days of US holidays, Seasonal trends \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c431698-3a61-4838-bb9b-0537ee552789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Size\n",
    "\n",
    "| Dataset                                    | Total Records       | Columns | Year | Size |\n",
    "| ------------------------------------------ | ---------- | ------- | ------|------|\n",
    "| **1-year merged OTPW + Weather + Airport** | 5.8M | 216     | 2015 | 1.4 GB |\n",
    "| **3-month subset**                         | 1.4M | 216     | 2015 | 0.34 GB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "601333a6-f1c0-405c-ad4c-c4b5d5a57797",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Data Dictionary Summary :\n",
    "| Category             | Example Fields                                             | Type                | Description                                    |\n",
    "| -------------------- | ---------------------------------------------------------- | ------------------- | ---------------------------------------------- |\n",
    "| **Data Time Fields**     | YEAR, QUARTER, MONTH, DAY_OF_MONTH, DAY_OF_WEEK, FL_DATE, CRS_DEP_TIME, DEP_TIME, DEP_TIME_BLK, CRS_ARR_TIME, ARR_TIME, ARR_TIME_BLK,FIRST_DEP_TIME, sched_depart_date_time, sched_depart_date_time_UTC,two_hours_prior_depart_UTC, four_hours_prior_depart_UTC, DATE                        | Integer/ Numeric/ Text           | Scheduled & actual operational timestamps      |\n",
    "| **Flight IDs**     | OP_UNIQUE_CARRIER, OP_CARRIER, OP_CARRIER_AIRLINE_ID, TAIL_NUM, OP_CARRIER_FL_NUM                  | Numeric             | Airline Id's |\n",
    "| **Airport and Station Metadata**     | ORIGIN_AIRPORT_ID, ORIGIN_AIRPORT_SEQ_ID, ORIGIN_CITY_MARKET_ID, ORIGIN, ORIGIN_CITY_NAME, ORIGIN_STATE_ABR, ORIGIN_STATE_FIPS, ORIGIN_STATE_NM, ORIGIN_WAC, origin_airport_name, origin_station_name, origin_station_id, origin_iata_code, origin_icao, origin_type, origin_region, origin_station_lat, origin_station_lon, origin_airport_lat, origin_airport_lon, origin_station_dis, DEST_AIRPORT_ID, DEST_AIRPORT_SEQ_ID, DEST_CITY_MARKET_ID, DEST, DEST_CITY_NAME, DEST_STATE_ABR, DEST_STATE_FIPS, DEST_STATE_NM, DEST_WAC, dest_airport_name, dest_station_name, dest_station_id, dest_iata_code, dest_icao, dest_type, dest_region, dest_station_lat, dest_station_lon, dest_airport_lat, dest_airport_lon, dest_station_dis                  | Numeric             | Geographic, administrative, and station-level metadata describing the origin and destination airports (IDs, location, airport type, region, coordinates, and station proximity) |\n",
    "| **Performance & Delay Fields** | **Departure:** DEP_DELAY, DEP_DELAY_NEW, DEP_DEL15, DEP_DELAY_GROUP, TAXI_OUT, WHEELS_OFF  <br> **Arrival:** ARR_DELAY, ARR_DELAY_NEW, ARR_DEL15, ARR_DELAY_GROUP, WHEELS_ON, TAXI_IN <br> **Elapsed Time:** CRS_ELAPSED_TIME, ACTUAL_ELAPSED_TIME, AIR_TIME, TOTAL_ADD_GTIME, LONGEST_ADD_GTIME <br> **Other Operational:** FLIGHTS, DISTANCE, DISTANCE_GROUP | Numeric / Categorical | Captures departure and arrival delays, taxi times, wheels-on/off timestamps, air time, scheduled vs. actual elapsed time, and flight distance. These fields describe the operational performance of each flight and are central to delay modeling. |\n",
    "| **Cancellation & Diversion**   | CANCELLED, CANCELLATION_CODE, DIVERTED                                                                                                                                                                                                                                                                                                                         | Numeric / Categorical | Indicates whether a flight was cancelled or diverted, along with cancellation reasons.                                                                                                                                                             |\n",
    "| **Delay Attribution Fields**   | CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY                                                                                                                                                                                                                                                                                   | Numeric               | Breakdown of delay causes across airline, weather, airspace system, security, and aircraft rotation factors.                                                                                                                                       |\n",
    "| **Weather Fields** | **Station Metadata:** STATION, LATITUDE, LONGITUDE, ELEVATION, NAME, REPORT_TYPE, SOURCE <br><br> **Atmospheric:** HourlyAltimeterSetting, HourlySeaLevelPressure, HourlyStationPressure, HourlyPressureChange, HourlyPressureTendency <br><br> **Temperature & Humidity:** HourlyDryBulbTemperature, HourlyWetBulbTemperature, HourlyDewPointTemperature, HourlyRelativeHumidity <br><br> **Wind:** HourlyWindDirection, HourlyWindSpeed, HourlyWindGustSpeed <br><br> **Visibility & Precipitation:** HourlyVisibility, HourlyPrecipitation, HourlyPresentWeatherType, REM | Numeric / Text / Categorical | Hourly weather observations from ASOS stations including pressure, temperature, humidity, wind, visibility, and precipitation. Also includes weather station metadata and special remarks. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55662e3c-6969-48a9-aff6-b506cea775be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Workflow Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dfee55b-3583-411e-a973-22416f8ed0d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/ML_Pipeline.png?raw=true\" width=\"950\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b459ba92-629b-4005-bc6d-25ac83723694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Summary Statistics\n",
    "\n",
    "**1. Flight Delay**\n",
    "\n",
    "**3 Months**\n",
    "\n",
    "| Summary | DEP_DELAY           | DEP_DELAY_NEW       | DEP_DELAY_GROUP    | TAXI_OUT | WHEELS_OFF        | DEP_TIME          | CRS_DEP_TIME      |\n",
    "|---------|----------------------|----------------------|---------------------|----------|---------------------|--------------------|--------------------|\n",
    "| count   | 1,359,057            | 1,359,057            | 1,359,057           | 1,358,244 | 1,358,244          | 1,359,057          | 1,401,363          |\n",
    "| mean    | 10.356973254249086   | 13.018863079326326   | 0.10478736359107822 | 16.396356619281956 | 1360.2707805077732 | 1337.0941873666814 | 1327.3694809981425 |\n",
    "| stddev  | 37.84557177171765    | 36.7668667774631      | 2.094169598462632   | 9.62962543055323    | 485.9576917932718  | 485.4186189667937  | 473.6824407220725  |\n",
    "| min     | -1.0                 | 0.0                   | -1                  | 1.0      | 1                   | 1                  | 1                  |\n",
    "| 25%     | -5.0                 | 0.0                   | -1.0                | 11.0     | 944.0              | 929.0              | 924.0              |\n",
    "| 50%     | -1.0                 | 0.0                   | -1.0                | 14.0     | 1345.0             | 1332.0             | 1322.0             |\n",
    "| 75%     | 9.0                  | 9.0                   | 0.0                 | 19.0     | 1748.0             | 1735.0             | 1725.0             |\n",
    "| max     | 996.0                | 996.0                 | 9                   | 99.0     | 959                | 959                | 959                |\n",
    "\n",
    "**Percentage of Flights Delayed Over 15 Minutes**\n",
    "| pct_delayed_over_15min |\n",
    "|-------------------------|\n",
    "| 0.2040400071520179      |\n",
    "\n",
    "**12 Months**\n",
    "\n",
    "| Summary | DEP_DELAY           | DEP_DELAY_NEW       | DEP_DELAY_GROUP     | TAXI_OUT | WHEELS_OFF        | DEP_TIME          | CRS_DEP_TIME      |\n",
    "|---------|----------------------|----------------------|----------------------|----------|---------------------|--------------------|--------------------|\n",
    "| count   | 5,725,795            | 5,725,795            | 5,725,795            | 5,722,904 | 5,722,904          | 5,725,795          | 5,811,854          |\n",
    "| mean    | 9.365873559916134    | 12.108813885233404   | 0.032435321208670584 | 16.076419768704838 | 1357.1905118450354 | 1335.2071237269236 | 1329.6055184799893 |\n",
    "| stddev  | 37.065179278827564   | 36.00620135669347    | 2.063704416291987    | 8.89893958787362    | 497.5173231494457  | 495.93153338409445 | 483.2460213641488  |\n",
    "| min     | -1.0                 | 0.0                   | -1                   | 1.0      | 1                   | 1                  | 1                  |\n",
    "| 25%     | -5.0                 | 0.0                   | -1.0                 | 11.0     | 936.0              | 921.0              | 917.0              |\n",
    "| 50%     | -2.0                 | 0.0                   | -1.0                 | 14.0     | 1343.0             | 1330.0             | 1325.0             |\n",
    "| 75%     | 7.0                  | 7.0                   | 0.0                  | 19.0     | 1754.0             | 1740.0             | 1730.0             |\n",
    "| max     | 999.0                | 999.0                 | 9                    | 99.0     | 959                | 959                | 959                |\n",
    "\n",
    "**Percentage of Flights Delayed Over 15 Minutes**\n",
    "\n",
    "| pct_delayed_over_15min |\n",
    "|-------------------------|\n",
    "| 0.18438225608845585     |\n",
    "\n",
    "\n",
    "\n",
    "_**Delay patterns are consistent across both datasets.**_\n",
    "Both 3-month and 1-year windows show a similar right-skewed delay distribution, with median delays around –1 to –2 minutes, meaning most flights depart on time or slightly early.\n",
    "\n",
    "_**The 3-month period has more major delays.**_\n",
    "About **20.4% of flights in the 3-month dataset** were delayed over 15 minutes, compared to **18.4% in the full-year dataset**—indicating the 3-month period had more operational disruptions (likely seasonality).\n",
    "\n",
    "**_Operational timing metrics are stable year-round._** \n",
    "Taxi-out time, wheels-off time, and scheduled departure times show very similar medians and variability in both datasets, confirming consistent airport operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20053281-0fde-4856-a335-dd0189bf1e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**2. Pressure Summary :**\n",
    "\n",
    "**3 Months**\n",
    "\n",
    "| Summary | HourlyAltimeterSetting | HourlySeaLevelPressure | HourlyStationPressure | HourlyPressureChange | HourlyPressureTendency |\n",
    "|---------|--------------------------|---------------------------|---------------------------|---------------------------|----------------------------|\n",
    "| count   | 1,338,148                | 1,247,907                 | 1,391,739                 | 471,407                   | 471,407                    |\n",
    "| mean    | 30.1215                  | 30.1300                   | 29.2279                   | 0.00137                   | 4.3913                     |\n",
    "| stddev  | 0.2008                   | 0.2098                    | 1.3502                    | 0.05033                   | 2.7951                     |\n",
    "| min     | 28.62                    | 28.63                     | 22.22                     | +0.00                     | 0                          |\n",
    "| 25%     | 29.99                    | 29.99                     | 29.13                     | -0.03                     | 2.0                        |\n",
    "| 50%     | 30.12                    | 30.12                     | 29.62                     | 0.00                      | 3.0                        |\n",
    "| 75%     | 30.25                    | 30.26                     | 29.99                     | 0.04                      | 8.0                        |\n",
    "| max     | 31.09                    | 31.18                     | 30.96                     | 0.17                      | 9                          |\n",
    "\n",
    "**12 Months**\n",
    "\n",
    "| Summary | HourlyAltimeterSetting | HourlySeaLevelPressure | HourlyStationPressure | HourlyPressureChange | HourlyPressureTendency |\n",
    "|---------|--------------------------|--------------------------|-------------------------|-------------------------|--------------------------|\n",
    "| count   | 5,564,390                | 5,242,010                | 5,773,364               | 1,996,935               | 1,996,935                |\n",
    "| mean    | 30.0328                  | 30.0224                  | 29.1480                 | 0.00237                 | 4.4510                   |\n",
    "| stddev  | 0.1877                   | 0.1985                   | 1.3212                  | 0.04172                 | 2.8207                   |\n",
    "| min     | 28.50                    | 28.57                    | 19.81                   | +0.00                   | 0                        |\n",
    "| 25%     | 29.92                    | 29.90                    | 29.05                   | -0.03                   | 2.0                      |\n",
    "| 50%     | 30.02                    | 30.01                    | 29.50                   | 0.00                    | 5.0                      |\n",
    "| 75%     | 30.14                    | 30.14                    | 29.91                   | 0.03                    | 8.0                      |\n",
    "| max     | 31.09                    | 31.18                    | 30.96                   | 0.20                    | 9                        |\n",
    "\n",
    "\n",
    "- The 3-month and 1-year summaries show highly consistent behavior in all pressure-related weather fields, with nearly identical medians and ranges. \n",
    "- The larger 1-year dataset naturally has more variation in minimum values and slightly lower means, but overall the distributions remain very stable. This confirms that the 3-month sample is representative of the full-year weather patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3a6c3b1-84e0-425e-9e54-1aa9268bde28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**3. Weather Feature**\n",
    "\n",
    "**3 Months**\n",
    "\n",
    "| summary | HourlyDryBulbTemperature | HourlyWetBulbTemperature | HourlyDewPointTemperature | HourlyRelativeHumidity | HourlyWindDirection | HourlyWindSpeed | HourlyWindGustSpeed | HourlyVisibility | HourlyPrecipitation |\n",
    "|---------|---------------------------|----------------------------|----------------------------|-------------------------|----------------------|-------------------|-----------------------|--------------------|-----------------------|\n",
    "| count   | 1,396,906                 | 1,391,105                  | 1,396,790                  | 1,396,642               | 1,395,292            | 1,396,717        | 182,027               | 1,397,276          | 1,242,335             |\n",
    "| mean    | 47.40                     | 40.87                      | 32.18                      | 60.50                   | 183.51               | 8.95             | 25.88                 | 9.01               | 0.0025                |\n",
    "| stddev  | 19.45                     | 16.79                      | 19.18                      | 22.05                   | 116.95               | 5.72             | 5.78                  | 2.41               | 0.0165                |\n",
    "| min     | *                         | *                          | *                          | *                       | 000                  | 0                | *                    | *                  | 0.00                  |\n",
    "| 25%     | 33                        | 29                         | 19                         | 44                      | 80                   | 5                | 22                   | 10                 | 0.0                   |\n",
    "| 50%     | 48                        | 42                         | 32                         | 62                      | 200                  | 8                | 25                   | 10                 | 0.0                   |\n",
    "| 75%     | 63                        | 54                         | 47                         | 78                      | 290                  | 13               | 29                   | 10                 | 0.0                   |\n",
    "| max     | 99                        | 9                          | 9                          | 99                      | VRB                  | 9s               | 64                    | 9.94               | T                     |\n",
    "\n",
    "\n",
    "**12 Months**\n",
    "\n",
    "| Summary | HourlyDryBulbTemperature | HourlyWetBulbTemperature | HourlyDewPointTemperature | HourlyRelativeHumidity | HourlyWindDirection | HourlyWindSpeed | HourlyWindGustSpeed | HourlyVisibility | HourlyPrecipitation |\n",
    "|---------|---------------------------|----------------------------|----------------------------|-------------------------|----------------------|-------------------|-----------------------|--------------------|-----------------------|\n",
    "| count   | 5,796,797                 | 5,771,328                  | 5,796,086                  | 5,795,830               | 5,786,726            | 5,794,760        | 738,781               | 5,797,612          | 5,172,810             |\n",
    "| mean    | 64.00                     | 55.28                      | 47.67                      | 60.38                   | 174.75               | 8.89             | 24.84                 | 9.39               | 0.0034                |\n",
    "| stddev  | 18.95                     | 15.96                      | 18.63                      | 21.46                   | 108.55               | 5.34             | 5.61                  | 1.88               | 0.0313                |\n",
    "| min     | *                         | *                          | *                          | *                       | 000                  | *                | *                    | *                  | 0.00                  |\n",
    "| 25%     | 53                        | 46                         | 35                         | 45                      | 80                   | 6                | 21                   | 10                 | 0.0                   |\n",
    "| 50%     | 67                        | 58                         | 51                         | 62                      | 180                  | 8                | 24                   | 10                 | 0.0                   |\n",
    "| 75%     | 78                        | 68                         | 63                         | 77                      | 270                  | 11               | 28                   | 10                 | 0.0                   |\n",
    "| max     | 99s                       | 9                          | 9s                         | 99                      | VRB                  | 9s               | 84                    | 99.42V             | TT                    |\n",
    "\n",
    "\n",
    "**_Temperature and humidity follow stable seasonal patterns:_**\n",
    "Both datasets show consistent distributions for dry-bulb, wet-bulb, dew point, and humidity. Medians are tightly centered (e.g., ~47°F dry-bulb for 3-month vs ~64°F for 1-year), reflecting normal seasonal variation.\n",
    "\n",
    "_**Most weather variables have low variability and no extreme outliers:**_\n",
    "Visibility is mostly at 10 miles, precipitation is almost always 0, and wind speeds cluster below 15 mph. Extreme values (e.g., “T”, “VRB”) appear rarely and were handled during cleaning.\n",
    "\n",
    "**_Weather data contains symbolic entries and measurement artifacts:_**\n",
    "Values like \"*\", \"TT\", \"VRB\", and \"9s\" appear in raw fields across temperature, wind, and pressure data. These required cleaning and numeric conversion before modeling.\n",
    "\n",
    "**_Missingness in weather features varies widely:_**\n",
    "Some features (e.g., hourly winds, temperatures, humidity) are highly complete, while others like gust speed and precipitation have large gaps. These were imputed where reasonable or excluded if sparsity exceeded thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "445dbb5f-1265-4642-8370-4e07252f0390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Analysis\n",
    "**Missing Value Analysis**\n",
    "\n",
    "| **3 Months** | **12 Months** |\n",
    "|-----------------------------------------|----------------------------------------|\n",
    "| ![](https://raw.githubusercontent.com/ericwu2024/w261/dac9afe96b18c37ee6937282bf73028d88ccf585/missing_values_assessment.png) | ![](https://github.com/ericwu2024/w261/blob/main/missping-value_percentage.png?raw=1) |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Dropped**: Columns with > 12% missing data were excluded due to insufficient information for modeling.\n",
    "- **Imputed**: Columns with 0.1% to 12% missing data were imputed using appropriate statistical techniques to preserve valuable features.\n",
    "- **Kept**: Columns with 0% missing data were retained as-is.\n",
    "\n",
    "**Other Quality Checks**\n",
    "\n",
    "- **Duplicates:** The dataset was validated and cleared of duplicate records.\n",
    "- **Invalid Data Types:** We addressed and corrected fields containing non-numeric/invalid entries (e.g., '*', 'TT', 'VRB') to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60fb890e-94e6-47fa-a869-2dd6031f587a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef148ad7-fa45-4533-934e-0f536b84d270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Distribution of Delay vs. Non-Delay records\n",
    "To begin with our EDA, we created a binary target variable `IS_DELAY` derived from Departure Delay Group (`DEP_DELAY_GROUP`). All flights that arrived early (values < 0) or on time (value = 0) were mapped to No Delay (0), while any positive delay value was mapped to Delay (1).\n",
    "\n",
    "| Departure Delay Group | IS_DELAYED    |\n",
    "|:---------------------:|:-------------:|\n",
    "| negative (-1, -2,...) | 0 (No Delay)  |\n",
    "|      0                | 0 (No Delay)  |\n",
    "| postive (1, 2, ...)   | 1 (Delay   )  |\n",
    "\n",
    "\n",
    "\n",
    "The following charts show the distribution of Delay versus Non-Delay flights. In both the 3-month and 1-year datasets, Non-Delay flights take up about 80% of total records after removing cancelled flights. In the modeling phase, we will consider incorporating the class distribution into our model and applying appropriate regularization and other imbalance-handling techniques to address this issue.\n",
    "\n",
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/DelayDistribution3m.png?raw=true\" width=\"450\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/DelayDistribution1y.png?raw=true\" width=\"450\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22210a98-1333-4c5f-89be-c8d7a58d69e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Correlation Analysis\n",
    "\n",
    "In this section, we measured the linear relationship between Departure Delay Time and numerous quantitative features using Pearson Correlation. Pearson correlation provides a straightforward way to measure the linear relationship between two quantitative variables. The result can inform our baseline linear model - logistic regression.\n",
    "\n",
    "The following barplots is a summary of the correlation matrix where it displays the highest correlated variables. \n",
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/CorrelationBarPlot3m.png?raw=true\" width=\"450\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/CorrelationBarPlot1y.png?raw=true\" width=\"450\">\n",
    "</div>\n",
    "\n",
    "- Several weather variables show strong correlation with the target variable—Departure Delay Time (minutes)—including `HourlyRelativeHumidity`, `HourlyWindSpeed`, `HourlyPrecipitation`, `HourlyVisibility`, and `HourlyDryBulbTemperature`. These relationships are expected, as adverse weather conditions often lead to operational slowdowns and increased departure delays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cfe0828-56f6-4cb9-b123-4817b6923a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Time Series Decomposition for Total Departure\n",
    "The following graphs are time series decompositions of the delay rate for both the 3-month dataset (left) and the 1-year dataset (right). In both plots, the x-axis represents flight dates, and **the y-axis represents the proportion of delayed flights**. Each time series is broken into three components: trend, seasonality, and residual.\n",
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/TimeSeries3m.png?raw=true\" width=\"490\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/TimeSeries1y.png?raw=true\" width=\"490\">\n",
    "</div>\n",
    "\n",
    "- In the 3-month view, the trend shows a clear peak around early January and February, which may reflect holiday traffic and early-year travel behavior. In contrast, the 1-year trend reveals additional dynamics: delays rise again during the summer months, likely driven by higher travel volume and weather-related impacts. The trend then dips in the fall and rises again approaching December, consistent with holiday travel patterns.\n",
    "- The seasonality component exhibits a repeating cyclical structure in both datasets. The pattern appears consistent and is likely tied to weekly operational cycles, such as weekday vs. weekend travel demand, staffing schedules, or recurring airport congestion patterns.\n",
    "\n",
    "\n",
    "As of the daily pattern, the time plots show the average delay rate for each half hour bucket across the entire day. Both 3 month and 1 year plots exhibit a similar pattern. \n",
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/AverageDelayRateByDay3m.png?raw=true\" width=\"490\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/AverageDelayRateByDay1y.png?raw=true\" width=\"490\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/PctSampleSize.png?raw=true\" width=\"490\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/PctSampleSize1y.png?raw=true\" width=\"490\">\n",
    "</div>\n",
    "\n",
    "\n",
    "- During late-night / early morning hours (00:00-03:30), the delay probability fluctuates significantly, which is likely driven by the small sample size at these times (See Percentage of Sample Size plots. Almost 0% of data are during 00:00 ~ 04:00). The sharp drop to near zero around 03:00-03:30, followed by the spike at 04:00, is potentially because very few flights depart in the early overnight period, and many carriers begin their first morning departures around 04:00 after overnight maintenance and aircraft repositioning. This sparse flight activity naturally leads to more volatile delay rates in these time ranges.\n",
    "- Morning flights start with a very low delay probability because there are no accumulated delays from earlier operations, and overall traffic volume is low. As the day progresses, increasing runaway congestion, heavier air traffic, connecting flights dependencies, and tighter spacing and sequencing contribute to building up delays. Peak is typically around 18:00-20:00.\n",
    "- The delay risk drops after 21:00 because flight volume declines, runway and airspace congestion reduces, and the system has more operational slack to absorb any remaining delays.\n",
    "- Because the departure delay rate follows a cyclical pattern throughout the day, these observations may support including Scheduled Departure Time as a time-based predictive feature in the ML model. We will further examine this feature and consider its implementation during Phase 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a4fbc46-c24b-4b5f-98d7-78d5985c976f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Principal Component Analysis (PCA)\n",
    "PCA is a non-supervised dimension reduction method that extracts variables contributing to the most variability. It is a valuable feature selection option when the data has many features. We ran the PCA and the **top 20 variables** for both three month and one year data collectively explains 70% of the variance. \n",
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/PCAcumulative.png?raw=true\" width=\"450\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/PCAcumulative1y.png?raw=true\" width=\"450\">\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"display: flex; gap: 20px;\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/PCAtop203m.png?raw=true\" width=\"450\">\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/PCAtop201y.png?raw=true\" width=\"450\">\n",
    "</div>\n",
    "Some variables also appear in the previous slide where they are high correlated with flight delay, such as Hourly Dry and Wet Bulb Temperature. These variables will be part of the inputs into the baseline as well as our second and third models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b127c13-b395-41b3-9a73-7733b71a5711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lasso Regularization\n",
    "\n",
    "We also used Lasso regularization (L1 penalty) to efficiently select relevant features from a high-dimensional dataset for classifying flight departure delays. Lasso is valuable when the dataset contains many correlated or low-contributing variables, as it automatically drives uninformative coefficients to exactly zero, facilitating feature selection.\n",
    "\n",
    "**Methodology and Rationale**\n",
    "- Model Training: Ran Lasso regression on one year of historical flight data, including operational, temporal, and meteorological features.\n",
    "- Feature Selection: Extracted feature coefficients and ranked variables by their absolute values to pinpoint those with the strongest predictive signal.\n",
    "- Automatic Elimination: Removed features with zero or near-zero coefficients—these contribute negligibly to the model’s predictive performance and can introduce noise or overfitting.\n",
    "- Efficiency Benefits: Since our dataset included many one-hot encoded fields (e.g., regions, airports), Lasso offered a streamlined path to essential variables, reducing model complexity and improving future training and interpretability.\n",
    "\n",
    "**Feature Coefficient Results & Recommendations**\n",
    "Below are representative Lasso coefficients from our model (non-zero and near-zero values):\n",
    "\n",
    "| Feature                   | Coefficient | Recommendation           |\n",
    "| ------------------------- | ----------- | ------------------------ |\n",
    "| HourlyRelativeHumidity    | 0.084       | Keep (predictive signal) |\n",
    "| day_of_week               | -0.057      | Likely useful; keep      |\n",
    "| HourlyWetBulbTemperature  | -0.037      | Keep                     |\n",
    "| HourlyDryBulbTemperature  | -0.035      | Keep                     |\n",
    "| dest_airport_lat          | -0.026      | Minor; consider keeping  |\n",
    "| dest_region_ohe           | 0.022       | Minor; consider keeping  |\n",
    "| dest_airport_lon          | 0.021       | Minor                    |\n",
    "| is_weekend                | 0.018       | Minor                    |\n",
    "| CRS_DEP_TIME              | 0.008       | Minor; likely useful     |\n",
    "| DAY_OF_MONTH              | -0.004      | Weak; consider dropping  |\n",
    "| DISTANCE                  | 0.0004      | Near zero; drop          |\n",
    "| OP_CARRIER_FL_NUM         | 0.0002      | Near zero; drop          |\n",
    "| (All below: exactly zero) | 0.0         | Drop                     |\n",
    "\n",
    "Features with exactly zero coefficients—such as HourlySeaLevelPressure, origin_region_ohe, DISTANCE_GROUP, month, and related one-hot fields—were identified by Lasso as non-contributory for prediction and removed from subsequent modeling steps.\n",
    "\n",
    "**Next Steps**\n",
    "Using Lasso for automated feature selection improved modeling efficiency and interpretability. The resulting trimmed feature set prepares the data for robust modeling with ensemble methods like XGBoost, and supports meaningful time-based train/test splits for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91f3ce67-9d27-47c0-80a1-77bd700acc42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Modeling Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efc5c7f6-050d-4e81-95db-1adb4096ed7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Pipeline overview\n",
    "For our baseline model, Logistic Regression, and our subsequent ensemble models (Random Forest Classifier + gradient boosted XGBoost Classifier) all use the following:\n",
    "\n",
    "- **Target label**:  \n",
    "  `DEP_DELAY_GROUP_CLASSIFIED ∈ {delayed, not_delayed}`  \n",
    "  where  \n",
    "`delayed = DEP_DELAY_GROUP >= 1`  \n",
    "`not_delayed = DEP_DELAY_GROUP <= 0`  \n",
    "as mentioned in the EDA section.\n",
    "\n",
    "- **Goal**: maximize **recall for the delayed class**, while monitoring F1 and precision to avoid a model that simply “cries delay” on every flight.\n",
    "\n",
    "The high-level pipeline to a model is: <br>\n",
    "| Stage                          | Purpose                                                | Key details / examples                                                                                          |\n",
    "|-------------------------------|--------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n",
    "| Raw data                      | Provide historical flights & weather context          | One year of OTPW flight records joined with hourly weather at departure airports                                 |\n",
    "| Label engineering             | Define prediction target                               | Map `DEP_DELAY_GROUP` → {**delayed**, **not_delayed**}                                                           |\n",
    "| Feature engineering           | Build informative predictors                           | Date/time, route & distance, hourly weather, holiday/summer flags, season, one-hot IDs (`TAIL_NUM`, `ORIGIN`)   |\n",
    "| Train/validation/test split   | Respect time order & avoid leakage                    | Q1–Q3 for training + validation; Q4 held out as blind test                                                       |\n",
    "| Class weighting               | Address strong class imbalance                         | Inverse-frequency weights per class on Q1–Q3, scaled by exponent α                                               |\n",
    "| Modeling pipeline (Spark ML)  | Transform features and fit model                       | `StringIndexer` → `OneHotEncoder` (as needeD) → `VectorAssembler` → weighted `LogisticRegression` (binomial, Elastic Net)    |\n",
    "| (Secondary Branch) Evaluation (CV on Q1–Q3)      | Tune hyperparameters and assess generalization         | Time-aware rolling CV (Q1→Q2, Q1–Q2→Q3); metrics per fold: precision/recall/F1 for **delayed**; confusion matrix |\n",
    "| Final evaluation (Q4 test)    | Report blind test performance for business decisions   | Train best model on Q1–Q3; compute precision, recall, F1 (delayed) and confusion matrix on Q4                   |\n",
    "\n",
    "Note: In this one year dataset, quarter 1 (Q1) is January to March, Q2 is April to June, Q3 is July to September, and Q4 is October to December.\n",
    "\n",
    "Shared Diagram:\n",
    "\n",
    "  <img src=\"https://github.com/ericwu2024/w261/blob/main/Phase2%20-%20model_diagram.png?raw=true\" width=\"700\">\n",
    "\n",
    "\n",
    "#### 2. Input feature families\n",
    "After all joins and feature engineering, the schema used for modeling is:<br>\n",
    "| Feature name               | Type    |\n",
    "|---------------------------|---------|\n",
    "| DEP_DELAY_GROUP           | integer |\n",
    "| QUARTER                   | integer |\n",
    "| DAY_OF_MONTH              | integer |\n",
    "| DAY_OF_WEEK               | integer |\n",
    "| DISTANCE                  | double  |\n",
    "| ORIGIN_AIRPORT_ID         | integer |\n",
    "| DEP_TIME                  | integer |\n",
    "| TAIL_NUM_ohe              | vector  |\n",
    "| ORIGIN_ohe                | vector  |\n",
    "| DEST_AIRPORT_ID           | integer |\n",
    "| HourlyPrecipitation       | double  |\n",
    "| HourlySeaLevelPressure    | double  |\n",
    "| HourlyAltimeterSetting    | double  |\n",
    "| HourlyWetBulbTemperature  | double  |\n",
    "| HourlyStationPressure     | double  |\n",
    "| HourlyWindSpeed           | double  |\n",
    "| HourlyRelativeHumidity    | double  |\n",
    "| HourlyDewPointTemperature | double  |\n",
    "| HourlyDryBulbTemperature  | double  |\n",
    "| HourlyVisibility          | double  |\n",
    "| HourlyWindDirection_deg   | double  |\n",
    "| is_us_holiday             | integer |\n",
    "| is_holiday_window         | integer |\n",
    "| is_summer_peak            | integer |\n",
    "| season                    | string  |\n",
    "| DEP_DELAY_GROUP_CLASSIFIED| string  |\n",
    "#### 3. Class imbalance and class weights\n",
    "On the training window (Q1–Q3), the label distribution is: <br>\n",
    "- delayed: 704,499 flights\n",
    "- not_delayed: 3,024,107 flights\n",
    "\n",
    "Total: 3,728,606 flights, so roughly: <br>\n",
    "Pr(delayed) = 18.9%, Pr(not_delayed) = 81.1%\n",
    "\n",
    "To address this imbalance, we use inverse-frequency class weights on the training set:<br>\n",
    "1. Let \\\\( n_c \\\\) be the number of training examples in class c, \\\\(N = \\sum_c n_c\\\\) be the total number of training examples,\n",
    "and K be the number of classes ((K=2) here).\n",
    "\n",
    "2. The base weight for class (c) is:\n",
    "$$(w_c^{(0)} = \\frac{N}{K , n_c})$$\n",
    "\n",
    "3. We then raise weights to a tunable exponent alpha:\n",
    "$$w_c = \\Bigl(w_c^{(0)}\\Bigr)^{\\alpha}$$\n",
    "\n",
    "- alpha = 1: standard inverse-frequency reweighting \n",
    "- alpha < 1: softer reweighting\n",
    "- alpha > 1: more aggressive up-weighting of rare classes\n",
    "\n",
    "\n",
    "#### 4. Metrics used\n",
    "We focus on binary metrics for the delayed class. <b>Our main objective is the Recall metric for delayed flights.</b> “If a flight is truly delayed, how often do we catch it?” <br>\n",
    "We also report F1 to summarize the trade-off between precision and recall and visualized on the True/False Positives/Negatives in a confusion matrix.\n",
    "\n",
    "The following are the calculations:  \n",
    "- **Precision**\n",
    "  - **Description:** The proportion of all classifications being actually positive\n",
    "  $$\n",
    "  \\mathrm{Precision} = \\frac{TP}{TP+FP}\n",
    "  $$\n",
    "- **Recall (Sensitivity/TPR)** The proportion of all actual positives that were classified correctly as positive.\n",
    "  - **Description:**\n",
    "  $$\n",
    "  \\mathrm{Recall} = \\frac{TP}{TP+FN}\n",
    "  $$\n",
    "\n",
    "- **F1-Score**\n",
    "  - **Description:** F1 Score calculates the harmonic mean between the Precision and Recall values.\n",
    "  $$\n",
    "  \\mathrm{F1} = 2*\\frac{Precision * Recall}{Precision + Recall}\n",
    "  $$ \n",
    "\n",
    "#### 5. Loss functions\n",
    "\n",
    "The following are the loss functions present in the models:\n",
    "\n",
    "For Logistic Regression and XGBoost\n",
    "- **Loss/Criteria:**  \n",
    "  - *Log Loss:*\n",
    "    $$\n",
    "      \\mathrm{LogLoss} = -\\frac{1}{N}\\sum_{i=1}^{N}\\Big[y_i\\log\\hat p_i+(1-y_i)\\log(1-\\hat p_i)\\Big]\n",
    "    $$ \n",
    "\n",
    "For Random Forest\n",
    "- **Loss/Criteria:**\n",
    "  - *Entropy (per tree):*\n",
    "    $$\n",
    "    H(S) = -\\sum_{k=1}^{K} p_k \\log p_k\n",
    "    $$\n",
    "  [The tree grows by maximizing impurity reduction (information gain).]\n",
    "\n",
    "The following are the regularization formulas used per our models:\n",
    "\n",
    "XGBoost using both Ridge and Lasso regularization where\n",
    "  \n",
    "- \uD835\uDF06: L2 (Ridge) regularization  \n",
    "- \uD835\uDEFC: L1 (Lasso) regularization  \n",
    "- γ: Leaf penalty\n",
    "\n",
    "$$\n",
    "\\Omega(f_t)\n",
    "=\n",
    "\\gamma T\n",
    "+\n",
    "\\frac{1}{2}\\lambda \\sum_{j=1}^{T} w_j^2\n",
    "+\n",
    "\\alpha \\sum_{j=1}^{T} |w_j|\n",
    "$$\n",
    "\n",
    "#### 6. Cluster Description\n",
    "  We are currently using a cluster noode of m5d.xlarge with a minimum of 2 workers and a maximum of 8 workers. Detailed approximate exevution time for the models are described in their respective sections below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dba9aa5-63cd-4a0c-81e8-1cc0edb0a123",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Logistic Regression Modeling Pipeline\n",
    "\n",
    "#### 1. Logistic regression loss function (with class weights & regularization)\n",
    "We use binary logistic regression with elastic net regularization in Spark ML, with hyperparameters:<br>\n",
    "\n",
    "- regParam (overall regularization strength)\n",
    "- elasticNetParam (mix between L1 and L2)\n",
    "\n",
    "In the baseline LR model we set regParam = 0.0 (no regularization).<br>\n",
    "In the tuned model we use the best values from grid search:<br>\n",
    "\n",
    "- regParam = 0.01 \n",
    "- elasticNetParam = 0.5 \n",
    "\n",
    "#### 2. Cross-validation setup and number of experiments\n",
    "We use time-aware rolling cross-validation on the training window (Q1–Q3): <br>\n",
    "\n",
    "- Fold 1: Train on Q1, Validate on Q2 \n",
    "- Fold 2: Train on Q1–Q2, Validate on Q3 \n",
    "\n",
    "Q4 is held out as a blind test set and is never used for model selection. <br>\n",
    "\n",
    "On top of several exploratory baseline runs, we perform a grid search over: <br>\n",
    "\n",
    "- alpha in {0.5, 1.0, 1.5} \n",
    "- regParam in {0.0, 10^{-4}, 10^{-3}, 10^{-2}\\} \n",
    "- elasticNetParam in \\{0.0, 0.5\\} \n",
    "\n",
    "This yields 3 * 4 * 2 = 24 logistic regression configurations.\n",
    "Each configuration is evaluated on 2 folds, so we run: <br>\n",
    "\n",
    "- 24 grid-search experiments × 2 folds \n",
    "- plus the baseline LR without class weights \n",
    "- plus the class-weighted LR with default parameters \n",
    "In total, we run on the order of ~26 logistic regression trainings in Phase 2.\n",
    "\n",
    "#### 3. Runtime\n",
    "\n",
    "•\tA single weighted logistic regression fit on Q1–Q3 takes on the order of 1–2 minutes. <br>\n",
    "•\tThe full grid search (24 configurations × 2 folds) completed in about 38 minutes wall-clock.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d39bf1e-9cd6-45c1-8360-2334b1c726ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Random Forest Modeling Pipeline (Ensemble)\n",
    "\n",
    "#### 1. Random Forest loss function (with class weights & regularization)\n",
    "Random Forest uses an ensemble of decision trees for binary classification. Class imbalance is handled via class weights (as a function) on the data before the model's execution, and regularization is controlled by tree depth, number of trees, and features.\n",
    "\n",
    "#### 2. Cross-validation setup and number of experiments\n",
    "Likewise to the Baseline Model (Logistic Regression), we used the rolling cross validation for the training window (Q1-Q3) where Q4 is held out for test. \n",
    "\n",
    "- Fold 1: Train on Q1, Validate on Q2\n",
    "- Fold 2: Train on Q1–Q2, Validate on Q3 \n",
    "\n",
    "Here is the parameter grid search space\n",
    "| Hyperparameter          | Values        |\n",
    "|-------------------------|----------------|\n",
    "| numTrees                | {100, 125}     |\n",
    "| maxDepth                | {6, 8}         |\n",
    "| maxBins                 | {32, 64}           |\n",
    "| featureSubsetStrategy   | {\"auto\"}       |\n",
    "\n",
    "Due to the use of 3 folds and a grid search space, there are a total of 2 × 2 × 2 × 1 = 8 configurations\n",
    "\n",
    "With cross validation, 4 configurations × 2 folds = 8 CV experiments.\n",
    "\n",
    "#### 3. Runtime\n",
    "A single Random Forest fit on Q1–Q3 typically takes 2–5 minutes depending on tree depth and number of estimators. The full grid search (all configurations × 2 folds) completes in under 1 hour (About 45 minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4544680-788c-419a-83f5-4c7e11eaddc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### XGBoost Modeling Pipeline (Gradient Boost - Ensemble)\n",
    "\n",
    "#### 1. XGBoost loss function (with class weights & regularization)\n",
    "XGBoost uses a gradient-boosted tree ensemble with a logistic loss for binary classification. Class imbalance was applied to the data (via a function) before executing the model per the respective class weights. Regularization is controlled by `lambda` (L2), `alpha` (L1), and tree-specific parameters.\n",
    "\n",
    "#### 2. Cross-validation setup and number of experiments\n",
    "Likewise to the Baseline Model (Logistic Regression), we used the rolling cross validation for the training window (Q1-Q3) where Q4 is held out for test. \n",
    "\n",
    "- Fold 1: Train on Q1, Validate on Q2\n",
    "- Fold 2: Train on Q1–Q2, Validate on Q3 \n",
    "\n",
    "The following is the paramter grid search space:\n",
    "| Hyperparameter      | Values               |\n",
    "|---------------------|----------------------|\n",
    "| max_depth           | {4, 6}              |\n",
    "| n_estimators        | {100, 150}          |\n",
    "| learning_rate       | {0.05, 0.1}         |\n",
    "| subsample           | {0.8, 1.0}          |\n",
    "| colsample_bytree    | {0.8, 1.0}          |\n",
    "| reg_lambda          | {1.0, 2.0}   (Experimental)       | \n",
    "| reg_alpha           | {0.0, 1.0}   (Experimental)       |\n",
    "\n",
    "Due to the use of 2 folds and a grid search space, there are a total of 2 × 2 × 2 × 2 × 2 × 2 × 2 = 128 total configurations\n",
    "\n",
    "With cross validation, 128 configurations × 2 folds = 256 CV experiments.\n",
    "\n",
    "Note: More parameters were considered and used, however, compute constraints were in full consideration to drop each hyperparameter down to 2.\n",
    "\n",
    "#### 3. Runtime\n",
    "A single XGBoost fit on Q1–Q3 typically takes 2–10 minutes depending on tree depth and number of estimators. The full grid search (all configurations × 2 folds) completes in about 5 hours. (With limited shared resources in consideration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44bf739a-a96f-4d4e-8d2c-8ecc0d9ee8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Results and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5e59b4f-3631-489c-b17c-fd4df7eb4685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Logistic Regression\n",
    "#### 1. Experiment table (logistic regression)\n",
    "Table 1 summarizes the 24 experiments we ran, varying alpha, regParam, and elasticNetParam. Each row shows the mean metrics over the two CV folds for the delayed class. <br>\n",
    "\n",
    "| Exp ID | alpha | regParam | elasticNetParam | mean_precision_delayed | mean_recall_delayed | mean_f1_delayed |\n",
    "|--------|:-----:|:--------:|:---------------:|:----------------------:|:-------------------:|:---------------:|\n",
    "| G01    | 0.5   | 0.0      | 0.0             | 0.3662                 | 0.2421              | 0.2834          |\n",
    "| G02    | 0.5   | 0.0      | 0.5             | 0.3662                 | 0.2421              | 0.2834          |\n",
    "| G03    | 0.5   | 0.0001   | 0.0             | 0.3658                 | 0.2417              | 0.2828          |\n",
    "| G04    | 0.5   | 0.0001   | 0.5             | 0.3619                 | 0.2435              | 0.2811          |\n",
    "| G05    | 0.5   | 0.001    | 0.0             | 0.3660                 | 0.2406              | 0.2820          |\n",
    "| G06    | 0.5   | 0.001    | 0.5             | 0.3715                 | 0.2224              | 0.2695          |\n",
    "| G07    | 0.5   | 0.01     | 0.0             | 0.3662                 | 0.2362              | 0.2788          |\n",
    "| G08    | 0.5   | 0.01     | 0.5             | 0.3656                 | 0.2067              | 0.2512          |\n",
    "| G09    | 1.0   | 0.0      | 0.0             | 0.2910                 | 0.5677              | 0.3797          |\n",
    "| G10    | 1.0   | 0.0      | 0.5             | 0.2910                 | 0.5677              | 0.3797          |\n",
    "| G11    | 1.0   | 0.0001   | 0.0             | 0.2913                 | 0.5681              | 0.3801          |\n",
    "| G12    | 1.0   | 0.0001   | 0.5             | 0.2889                 | 0.5756              | 0.3780          |\n",
    "| G13    | 1.0   | 0.001    | 0.0             | 0.2918                 | 0.5675              | 0.3803          |\n",
    "| G14    | 1.0   | 0.001    | 0.5             | 0.2927                 | 0.5751              | 0.3830          |\n",
    "| G15    | 1.0   | 0.01     | 0.0             | 0.2927                 | 0.5693              | 0.3814          |\n",
    "| G16    | 1.0   | 0.01     | 0.5             | 0.2763                 | 0.6355              | 0.3823          |\n",
    "| G17    | 1.5   | 0.0      | 0.0             | 0.2311                 | 0.8334              | 0.3601          |\n",
    "| G18    | 1.5   | 0.0      | 0.5             | 0.2311                 | 0.8334              | 0.3601          |\n",
    "| G19    | 1.5   | 0.0001   | 0.0             | 0.2311                 | 0.8338              | 0.3601          |\n",
    "| G20    | 1.5   | 0.0001   | 0.5             | 0.2303                 | 0.8391              | 0.3593          |\n",
    "| G21    | 1.5   | 0.001    | 0.0             | 0.2315                 | 0.8335              | 0.3605          |\n",
    "| G22    | 1.5   | 0.001    | 0.5             | 0.2286                 | 0.8583              | 0.3595          |\n",
    "| G23    | 1.5   | 0.01     | 0.0             | 0.2301                 | 0.8423              | 0.3597          |\n",
    "| G24    | 1.5   | 0.01     | 0.5             | 0.2103                 | **0.9253**          | 0.3418          |\n",
    "\n",
    "*Table 1 – Grid search results for delayed vs not_delayed (Q1–Q3, mean over 2 folds) via logistic regression*\n",
    "\n",
    "Per the formula in the above Class imbalance and weight section,\n",
    "The best configuration (by recall for the delayed class) in our grid search uses: <br>\n",
    "- alpha = 1.5 <br>\n",
    "\n",
    "Resulting approximate class weights on Q1–Q3: <br>\n",
    "- 'delayed': 4.304811866174949, <br>\n",
    "- 'not_delayed': 0.48403750921889904 <br>\n",
    "\n",
    "The best configuration (by F1 for the delayed class) in our grid search uses: <br>\n",
    "- alpha = 1.0 <br>\n",
    "\n",
    "Resulting approximate class weights on Q1–Q3: <br>\n",
    "- 'delayed': 2.6462819677529708, <br>\n",
    "- 'not_delayed': 0.616480501516646 <br>\n",
    "\n",
    "Key observations from the training / validation experiments:\n",
    "\n",
    "- Moderate reweighting (alpha = 0.5): mean recall(delayed) is around 0.24, with precision ≈ 0.36–0.37 and F1 ≈ 0.28. \n",
    "            The model is still relatively conservative in calling flights “delayed”.\n",
    "- Stronger reweighting (alpha = 1.0): recall(delayed) increases to around 0.57,precision drops to ≈ 0.29,F1 peaks around 0.3830 (G14: alpha=1.0, regParam=0.001, elasticNetParam=0.5). \n",
    "            This region (α=1.0) gives the best overall balance between catching delays and controlling false positives on Q1–Q3.\n",
    "- Very aggressive reweighting (α= 1.5): recall(delayed) climbs as high as 0.93 (G24), but precision drops to ≈ 0.21, F1 falls back to ≈ 0.34–0.36. \n",
    "            These settings treat delayed flights as extremely important, at the expense of many false alarms.\n",
    "\n",
    "#### 2. Blind test performance on Q4\n",
    "The original model does not handle imbalance class and it is trained with default parameters, here is the results with confusion matrix for this model:\n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/lr_original_results.png?raw=true\" width=\"700\">\n",
    "\n",
    "\n",
    "For the final model, we retrained logistic regression on the full Q1–Q3 training window using the hyper-parameters selected from the grid search:\n",
    "\n",
    "- Either best-Recall configuration (G24):\n",
    "\t        alpha = 1.5, regParam = 0.01, elasticNetParam = 0.5,\n",
    "\t        very high recall for delayed flights during CV, lower precision.\n",
    "- Or best-F1 configuration (G14)\n",
    "\t        alpha = 1.0, regParam = 0.001, elasticNetParam = 0.5,\n",
    "\t        better balance between recall and precision.\n",
    "\n",
    "The Q4 confusion matrix confirms the same broad pattern seen in cross-validation: the class-weighted logistic model substantially increases recall for delayed flights compared to the original unweighted baseline, but at the cost of misclassifying more not_delayed flights as delayed. <br>\n",
    "\n",
    "Here are the results with confusion matrix for each approach: <br>\n",
    "Best Recall configuration: <br>\n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/lr_best_recall_results.png?raw=true\" width=\"700\">\n",
    "\n",
    "Best F1 configuration: <br>\n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/lr_best_F1_results.png?raw=true\" width=\"700\">\n",
    "\n",
    "These are the final metric results with the optimal parameters.\n",
    "| Split        | F1        | Precision | Recall |\n",
    "|-------------|-----------|-----------|--------|\n",
    "| Train   (Q1 to 3)      | 0.3963 | 0.2863 | 0.6434 |\n",
    "| Validation (Cross)   | 0.3830    | 0.2927    | 0.5751 |\n",
    "| Test (Q4)     | 0.2986 | 0.2663 | 0.3397 |\n",
    "\n",
    "#### 3. Discussion\n",
    "\n",
    "##### 1. Impact of class weighting on detecting delayed flights\n",
    "The grid search clearly shows that class weighting is essential for this problem:\n",
    "\n",
    "- Without sufficiently strong weighting, logistic regression behaves like a standard accuracy-driven classifier and mostly learns the majority class pattern (not_delayed), leading to a low recall for delayed flights.\n",
    "- As we increase alpha from 0.5 → 1.0 → 1.5, the model increasingly prioritizes delayed flights\n",
    "This behavior matches intuition: up-weighting the minority class pushes the decision boundary to classify more flights as delayed. For an operations team that cares more about missing a true delay than about raising false alarms, the high-recall settings (e.g. α=1.5) are attractive, but they come with a substantial cost in precision.\n",
    "\n",
    "##### 2. Trade-off between recall and precision\n",
    "- High-recall / low-precision model (G24)\n",
    "\t        Useful if the system is used as a conservative early-warning tool, where false alarms are acceptable but missed delays are costly.\n",
    "- Balanced model (G14)\n",
    "\t        More appropriate if the prediction is used to trigger costly interventions (e.g., reassigning gates or proactively rebooking passengers), where too many false positives could overwhelm resources.\n",
    "\n",
    "##### 3. Generalization to Q4 and limitations\n",
    "The blind test on Q4 shows that the qualitative trade-off observed in cross-validation carries over to unseen future data:\n",
    "\n",
    "- The class-weighted logistic models continue to improve recall for delayed flights compared to the early baseline that ignored imbalance.\n",
    "- At the same time, high-recall settings maintain relatively low precision, implying many flights are flagged as delayed but will actually depart on time.\n",
    "\n",
    "Limitations of the current approach: <br>\n",
    "\t1.\tLinear decision boundary: logistic regression assumes a linear relationship between features and log-odds of delay. Complex interactions between schedule, route, and weather may not be fully captured. <br>\n",
    "\t2.\tNo explicit resampling: we only used class weighting, not over-/under-sampling strategies (e.g., down-sampling not_delayed or up-sampling delayed), which might further shape the trade-off and training dynamics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d8c618f-1690-4696-b4fb-302a08a5ade8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Random Forest Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07da8866-4ec3-42b9-bad1-72b8ae023d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Experiment table (Random Forest)\n",
    "Table 2 summarizes the grid search experiments for Random Forest, varying key hyperparameters. Each row shows mean metrics over CV folds per Q1-Q3 as previously described.\n",
    "| Exp ID | numTrees | maxDepth | maxBins | featureSubsetStrategy  | F1 Score | Precision | Recall |\n",
    "|--------|----------|----------|---------|------------------------|----------|-----------|--------|\n",
    "| RF01 | 100 | 6 | 32 | auto  | 0.6937 | 0.7052 | 0.6835 |\n",
    "| RF02 | 100 | 6 | 32 | auto | 0.6417 | 0.7762 | 0.5937 |\n",
    "| RF03 | 100 | 8 | 32 | auto |  0.7098 | 0.7194 | 0.7014 |\n",
    "| RF04 | 100 | 8 | 32 | auto |  0.6360 | 0.7775 | 0.5874 |\n",
    "| RF05 | 150 | 6 | 32 | auto |  0.6934 | 0.7048 | 0.6833 |\n",
    "| RF06 | 150 | 6 | 32 | auto |  0.6446 | 0.7753 | 0.5969 |\n",
    "| RF07 | 150 | 8 | 32 | auto | 0.7060 | 0.7190 | 0.6950 |\n",
    "| RF08 | 150 | 8 | 32 | auto |  0.6385 | 0.7777 | 0.5901 |\n",
    "\n",
    "*Table 2 – Grid search results for delayed vs not_delayed (Q1–Q3, mean over 2 folds) via random forest*\n",
    "\n",
    "The final optimal parameters for random forest is:\n",
    "| Exp ID | numTrees | maxDepth | maxBins | featureSubsetStrategy  | F1 Score | Precision | Recall |\n",
    "|--------|----------|----------|---------|------------------------|----------|-----------|--------|\n",
    "| RF03 | 100 | 8 | 32 | auto |  0.7098 | 0.7194 | 0.7014 |\n",
    "\n",
    "#### 2. Train/Validation/Test performance with the optimal parameters\n",
    "These are the final metric results with the optimal parameters.\n",
    "\n",
    "| Split        | F1        | Precision | Recall |\n",
    "|-------------|-----------|-----------|--------|\n",
    "| Train   (Q1 to 3)      | 0.6686 | 0.7670 | 0.6291 |\n",
    "| Validation (Cross)   | 0.7098    | 0.7194    | 0.7014 |\n",
    "| Test (Q4)     | 0.7353 | 0.7768 | 0.7074 |\n",
    "\n",
    "Confusion Matrix   \n",
    "Train:  \n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-rf-train.png?raw=true\" width=\"700\">\n",
    "\n",
    "Cross Validation Folds:  \n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-rf-q2.png?raw=true\" width=\"700\">\n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-rf-q3.png?raw=true\" width=\"700\">\n",
    "\n",
    "\n",
    "Final (Test Q4):  \n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-rf-final.png?raw=true\" width=\"700\">\n",
    "\n",
    "#### 3. Discussion\n",
    "\n",
    "##### 3.1. Impact of class weighting and tree depth on detecting delayed flights\n",
    "\n",
    "Just like Logistic Regression, the class weighting preprocessed onto the model shows more likely results of the prediction. The reason is prior to performing such strategy, random forest would be biased to predict not_delayed as the result from the class imbalance. \n",
    "\n",
    "With this weighting, the combination of running the grid search and using cross validation to select the best hyperparameters had grown out to a depth of 8 at 100 trees offered the most favorable balance to maintain the generalizability for a delayed flight prediction.\n",
    "\n",
    "##### 3.2. Trade-off between recall and precision\n",
    "\n",
    "With the model used on the blind Q4, the random forest model makes a balanced yet likely prediction of a flight being delayed or not. From the test result, recall and precision are 0.7074 and 0.7768 respectively. Although the recall metric shows that the preidction is above just a flip of a coin, the model maintains the precision on the Q4 data as much as possible. Even though we were not aiming for precision to be high, this overall best parameter model is favorable for our observation within 10% (0.1) of between the validation and test data.\n",
    "\n",
    "##### 3.3. Generalization to Q4 and limitations\n",
    "Our hyperparameter tuned random forest model clearly shows that it generalizes the predictions well while maintaining instances such as seasonal travel impacts which usually occures at the end of the year for the United States are not severely impacting the prediction. \n",
    "\n",
    "However, we do understand that using class weights may not be the ultimate solution but it is a practical solution at the moment. Because of seasonality across the quarters of the year, noise and extremes can occur such as unforeseen government shutdowns. \n",
    "\n",
    "Furthermore, as much as we want to expand the parameter search space, memory compute constraints per our cluster (mentioned in the pipelines section 6 above) restricted our ability to determine the best hyperparameters yet the grid search surprisingly determined the best hyperparamter model for random forest. Perhaps additional searches with a larger depth and and bins would perform better, while considering the instance of overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a4f6d2e-755a-4a1c-b9c6-fcbbf0195970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## XGBoost Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12087bc3-6d07-4d73-90c7-5b4ccae75225",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "#### 1. Experiment table (XGBoost)\n",
    "The following table (table 3) summarizes the grid search experiments for XGBoost, varying key hyperparameters. Each row shows mean metrics over CV folds per Q1-Q3 as previously described.\n",
    "\n",
    "| Exp ID | max_depth | n_estimators | learning_rate | subsample | colsample_bytree | lambda | alpha | precision | recall | f1 |\n",
    "|--------|-----------|--------------|----------------|-----------|-------------------|------------|-----------|----------------|--------------|----------|\n",
    "|X001|4|100|0.05|0.8|0.8|1.0|0.0|0.7601|0.6283|0.6648|\n",
    "|X002|4|100|0.05|0.8|0.8|1.0|1.0|0.7600|0.6266|0.6645|\n",
    "|X003|4|100|0.05|0.8|0.8|2.0|0.0|0.7597|0.6285|0.6658|\n",
    "|X004|4|100|0.05|0.8|0.8|2.0|1.0|0.7598|0.6264|0.6650|\n",
    "|X005|4|100|0.05|0.8|1.0|1.0|0.0|0.7598|0.6272|0.6640|\n",
    "|X006|4|100|0.05|0.8|1.0|1.0|1.0|0.7600|0.6255|0.6623|\n",
    "|X007|4|100|0.05|0.8|1.0|2.0|0.0|0.7597|0.6261|0.6646|\n",
    "|X008|4|100|0.05|0.8|1.0|2.0|1.0|0.7597|0.6278|0.6656|\n",
    "|X009|4|100|0.05|1.0|0.8|1.0|0.0|0.7600|0.6279|0.6646|\n",
    "|X010|4|100|0.05|1.0|0.8|1.0|1.0|0.7601|0.6271|0.6647|\n",
    "|X011|4|100|0.05|1.0|0.8|2.0|0.0|0.7600|0.6270|0.6646|\n",
    "|X012|4|100|0.05|1.0|0.8|2.0|1.0|0.7599|0.6268|0.6641|\n",
    "|X013|4|100|0.05|1.0|1.0|1.0|0.0|0.7595|0.6261|0.6645|\n",
    "|X014|4|100|0.05|1.0|1.0|1.0|1.0|0.7594|0.6267|0.6644|\n",
    "|X015|4|100|0.05|1.0|1.0|2.0|0.0|0.7597|0.6269|0.6642|\n",
    "|X016|4|100|0.05|1.0|1.0|2.0|1.0|0.7615|0.6264|0.6653|\n",
    "|X017|4|100|0.1|0.8|0.8|1.0|0.0|0.7623|0.6273|0.6639|\n",
    "|X018|4|100|0.1|0.8|0.8|1.0|1.0|0.7615|0.6259|0.6650|\n",
    "|X019|4|100|0.1|0.8|0.8|2.0|0.0|0.7623|0.6260|0.6633|\n",
    "|X020|4|100|0.1|0.8|0.8|2.0|1.0|0.7624|0.6261|0.6640|\n",
    "|X021|4|100|0.1|0.8|1.0|1.0|0.0|0.7614|0.6281|0.6661|\n",
    "|X022|4|100|0.1|0.8|1.0|1.0|1.0|0.7615|0.6298|0.6653|\n",
    "|X023|4|100|0.1|0.8|1.0|2.0|0.0|0.7615|0.6264|0.6658|\n",
    "|X024|4|100|0.1|0.8|1.0|2.0|1.0|0.7623|0.6288|0.6643|\n",
    "|X025|4|100|0.1|1.0|0.8|1.0|0.0|0.7622|0.6285|0.6662|\n",
    "|X026|4|100|0.1|1.0|0.8|1.0|1.0|0.7620|0.6279|0.6659|\n",
    "|X027|4|100|0.1|1.0|0.8|2.0|0.0|0.7617|0.6291|0.6662|\n",
    "|X028|4|100|0.1|1.0|0.8|2.0|1.0|0.7616|0.6281|0.6666|\n",
    "|X029|4|100|0.1|1.0|1.0|1.0|0.0|0.7615|0.6290|0.6654|\n",
    "|X030|4|100|0.1|1.0|1.0|1.0|1.0|0.7614|0.6293|0.6660|\n",
    "|X031|4|100|0.1|1.0|1.0|2.0|0.0|0.7618|0.6281|0.6662|\n",
    "|X032|4|100|0.1|1.0|1.0|2.0|1.0|0.7615|0.6289|0.6658|\n",
    "|X033|4|150|0.05|0.8|0.8|1.0|0.0|0.7617|0.6282|0.6659|\n",
    "|X034|4|150|0.05|0.8|0.8|1.0|1.0|0.7612|0.6276|0.6650|\n",
    "|X035|4|150|0.05|0.8|0.8|2.0|0.0|0.7613|0.6267|0.6653|\n",
    "|X036|4|150|0.05|0.8|0.8|2.0|1.0|0.7612|0.6282|0.6652|\n",
    "|X037|4|150|0.05|0.8|1.0|1.0|0.0|0.7614|0.6261|0.6640|\n",
    "|X038|4|150|0.05|0.8|1.0|1.0|1.0|0.7613|0.6275|0.6650|\n",
    "|X039|4|150|0.05|0.8|1.0|2.0|0.0|0.7613|0.6270|0.6652|\n",
    "|X040|4|150|0.05|0.8|1.0|2.0|1.0|0.7614|0.6266|0.6636|\n",
    "|X041|4|150|0.05|1.0|0.8|1.0|0.0|0.7618|0.6265|0.6644|\n",
    "|X042|4|150|0.05|1.0|0.8|1.0|1.0|0.7622|0.6270|0.6644|\n",
    "|X043|4|150|0.05|1.0|0.8|2.0|0.0|0.7617|0.6261|0.6646|\n",
    "|X044|4|150|0.05|1.0|0.8|2.0|1.0|0.7611|0.6265|0.6643|\n",
    "|X045|4|150|0.05|1.0|1.0|1.0|0.0|0.7611|0.6267|0.6648|\n",
    "|X046|4|150|0.05|1.0|1.0|1.0|1.0|0.7610|0.6270|0.6642|\n",
    "|X047|4|150|0.05|1.0|1.0|2.0|0.0|0.7614|0.6269|0.6646|\n",
    "|X048|4|150|0.05|1.0|1.0|2.0|1.0|0.7621|0.6261|0.6660|\n",
    "|X049|4|150|0.1|0.8|0.8|1.0|0.0|0.7635|0.6269|0.6639|\n",
    "|X050|4|150|0.1|0.8|0.8|1.0|1.0|0.7630|0.6273|0.6653|\n",
    "|X051|4|150|0.1|0.8|0.8|2.0|0.0|0.7627|0.6300|0.6673|\n",
    "|X052|4|150|0.1|0.8|0.8|2.0|1.0|0.7621|0.6279|0.6652|\n",
    "|X053|4|150|0.1|0.8|1.0|1.0|0.0|0.7626|0.6271|0.6643|\n",
    "|X054|4|150|0.1|0.8|1.0|1.0|1.0|0.7621|0.6302|0.6674|\n",
    "|X055|4|150|0.1|0.8|1.0|2.0|0.0|0.7620|0.6305|0.6682|\n",
    "|X056|4|150|0.1|0.8|1.0|2.0|1.0|0.7623|0.6315|0.6671|\n",
    "|X057|4|150|0.1|1.0|0.8|1.0|0.0|0.7623|0.6296|0.6668|\n",
    "|X058|4|150|0.1|1.0|0.8|1.0|1.0|0.7623|0.6308|0.6679|\n",
    "|X059|4|150|0.1|1.0|0.8|2.0|0.0|0.7628|0.6317|0.6675|\n",
    "|X060|4|150|0.1|1.0|0.8|2.0|1.0|0.7623|0.6307|0.6683|\n",
    "|X061|4|150|0.1|1.0|1.0|1.0|0.0|0.7631|0.6294|0.6660|\n",
    "|X062|4|150|0.1|1.0|1.0|1.0|1.0|0.7626|0.6287|0.6658|\n",
    "|X063|4|150|0.1|1.0|1.0|2.0|0.0|0.7630|0.6289|0.6666|\n",
    "|X064|4|150|0.1|1.0|1.0|2.0|1.0|0.7611|0.6292|0.6670|\n",
    "|X065|6|100|0.05|0.8|0.8|1.0|0.0|0.7607|0.6331|0.6694|\n",
    "|X066|6|100|0.05|0.8|0.8|1.0|1.0|0.7607|0.6321|0.6684|\n",
    "|X067|6|100|0.05|0.8|0.8|2.0|0.0|0.7608|0.6326|0.6690|\n",
    "|X068|6|100|0.05|0.8|0.8|2.0|1.0|0.7606|0.6310|0.6676|\n",
    "|X069|6|100|0.05|0.8|1.0|1.0|0.0|0.7609|0.6334|0.6703|\n",
    "|X070|6|100|0.05|0.8|1.0|1.0|1.0|0.7601|0.6338|0.6706|\n",
    "|X071|6|100|0.05|0.8|1.0|2.0|0.0|0.7603|0.6337|0.6705|\n",
    "|X072|6|100|0.05|0.8|1.0|2.0|1.0|0.7605|0.6356|0.6708|\n",
    "|X073|6|100|0.05|1.0|0.8|1.0|0.0|0.7613|0.6330|0.6698|\n",
    "|X074|6|100|0.05|1.0|0.8|1.0|1.0|0.7608|0.6321|0.6681|\n",
    "|X075|6|100|0.05|1.0|0.8|2.0|0.0|0.7612|0.6311|0.6686|\n",
    "|X076|6|100|0.05|1.0|0.8|2.0|1.0|0.7608|0.6321|0.6694|\n",
    "|X077|6|100|0.05|1.0|1.0|1.0|0.0|0.7596|0.6342|0.6703|\n",
    "|X078|6|100|0.05|1.0|1.0|1.0|1.0|0.7601|0.6333|0.6690|\n",
    "|X079|6|100|0.05|1.0|1.0|2.0|0.0|0.7604|0.6322|0.6693|\n",
    "|X080|6|100|0.05|1.0|1.0|2.0|1.0|0.7615|0.6337|0.6711|\n",
    "|X081|6|100|0.1|0.8|0.8|1.0|0.0|0.7624|0.6344|0.6716|\n",
    "|X082|6|100|0.1|0.8|0.8|1.0|1.0|0.7615|0.6370|0.6728|\n",
    "|X083|6|100|0.1|0.8|0.8|2.0|0.0|0.7619|0.6351|0.6703|\n",
    "|X084|6|100|0.1|0.8|0.8|2.0|1.0|0.7613|0.6333|0.6710|\n",
    "|X085|6|100|0.1|0.8|1.0|1.0|0.0|0.7617|0.6381|0.6714|\n",
    "|X086|6|100|0.1|0.8|1.0|1.0|1.0|0.7619|0.6337|0.6713|\n",
    "|X087|6|100|0.1|0.8|1.0|2.0|0.0|0.7605|0.6377|0.6735|\n",
    "|X088|6|100|0.1|0.8|1.0|2.0|1.0|0.7619|0.6375|0.6717|\n",
    "|X089|6|100|0.1|1.0|0.8|1.0|0.0|0.7616|0.6349|0.6719|\n",
    "|X090|6|100|0.1|1.0|0.8|1.0|1.0|0.7623|0.6368|0.6723|\n",
    "|X091|6|100|0.1|1.0|0.8|2.0|0.0|0.7622|0.6335|0.6705|\n",
    "|X092|6|100|0.1|1.0|0.8|2.0|1.0|0.7613|0.6344|0.6700|\n",
    "|X093|6|100|0.1|1.0|1.0|1.0|0.0|0.7614|0.6352|0.6717|\n",
    "|X094|6|100|0.1|1.0|1.0|1.0|1.0|0.7607|0.6353|0.6715|\n",
    "|X095|6|100|0.1|1.0|1.0|2.0|0.0|0.7609|0.6374|0.6725|\n",
    "|X096|6|100|0.1|1.0|1.0|2.0|1.0|0.7613|0.6361|0.6711|\n",
    "|X097|6|150|0.05|0.8|0.8|1.0|0.0|0.7620|0.6350|0.6714|\n",
    "|X098|6|150|0.05|0.8|0.8|1.0|1.0|0.7619|0.6351|0.6707|\n",
    "|X099|6|150|0.05|0.8|0.8|2.0|0.0|0.7620|0.6339|0.6697|\n",
    "|X100|6|150|0.05|0.8|0.8|2.0|1.0|0.7621|0.6324|0.6704|\n",
    "|X101|6|150|0.05|0.8|1.0|1.0|0.0|0.7611|0.6368|0.6726|\n",
    "|X102|6|150|0.05|0.8|1.0|1.0|1.0|0.7611|0.6359|0.6717|\n",
    "|X103|6|150|0.05|0.8|1.0|2.0|0.0|0.7607|0.6364|0.6722|\n",
    "|X104|6|150|0.05|0.8|1.0|2.0|1.0|0.7617|0.6357|0.6710|\n",
    "|X105|6|150|0.05|1.0|0.8|1.0|0.0|0.7624|0.6333|0.6700|\n",
    "|X106|6|150|0.05|1.0|0.8|1.0|1.0|0.7620|0.6341|0.6695|\n",
    "|X107|6|150|0.05|1.0|0.8|2.0|0.0|0.7621|0.6320|0.6696|\n",
    "|X108|6|150|0.05|1.0|0.8|2.0|1.0|0.7619|0.6340|0.6709|\n",
    "|X109|6|150|0.05|1.0|1.0|1.0|0.0|0.7610|0.6364|0.6721|\n",
    "|X110|6|150|0.05|1.0|1.0|1.0|1.0|0.7611|0.6353|0.6713|\n",
    "|X111|6|150|0.05|1.0|1.0|2.0|0.0|0.7610|0.6347|0.6711|\n",
    "|X112|6|150|0.05|1.0|1.0|2.0|1.0|0.7621|0.6354|0.6725|\n",
    "|X113|6|150|0.1|0.8|0.8|1.0|0.0|0.7621|0.6369|0.6718|\n",
    "|X114|6|150|0.1|0.8|0.8|1.0|1.0|0.7621|0.6350|0.6722|\n",
    "|X115|6|150|0.1|0.8|0.8|2.0|0.0|0.7627|0.6359|0.6709|\n",
    "|X116|6|150|0.1|0.8|0.8|2.0|1.0|0.7623|0.6347|0.6719|\n",
    "|X117|6|150|0.1|0.8|1.0|1.0|0.0|0.7617|0.6392|0.6753|\n",
    "|X118|6|150|0.1|0.8|1.0|1.0|1.0|0.7619|0.6386|0.6732|\n",
    "|X119|6|150|0.1|0.8|1.0|2.0|0.0|0.7613|0.6393|0.6744|\n",
    "|X120|6|150|0.1|0.8|1.0|2.0|1.0|0.7617|0.6396|0.6738|\n",
    "|X121|6|150|0.1|1.0|0.8|1.0|0.0|0.7620|0.6375|0.6740|\n",
    "|X122|6|150|0.1|1.0|0.8|1.0|1.0|0.7626|0.6390|0.6728|\n",
    "|X123|6|150|0.1|1.0|0.8|2.0|0.0|0.7626|0.6352|0.6720|\n",
    "|X124|6|150|0.1|1.0|0.8|2.0|1.0|0.7618|0.6369|0.6720|\n",
    "|X125|6|150|0.1|1.0|1.0|1.0|0.0|0.7616|0.6357|0.6726|\n",
    "|X126|6|150|0.1|1.0|1.0|1.0|1.0|0.7616|0.6359|0.6711|\n",
    "|X127|6|150|0.1|1.0|1.0|2.0|0.0|0.7611|0.6386|0.6739|\n",
    "|X128|6|150|0.1|1.0|1.0|2.0|1.0|0.7823|0.6380|0.6422|\n",
    "\n",
    "*Table 3 – Grid search results for delayed vs not_delayed (Q1–Q3, mean over 2 folds) via xgboost*\n",
    "\n",
    "Our best XGBoost model is the following: (Optimized for best recall)\n",
    "| Exp ID | max_depth | n_estimators | learning_rate | subsample | colsample_bytree | lambda | alpha | precision | recall | f1 |\n",
    "|--------|-----------|--------------|----------------|-----------|-------------------|------------|-----------|----------------|--------------|----------|\n",
    "|X120|6|150|0.1|0.8|1.0|2.0|1.0|0.7617|0.6396|0.6738|\n",
    "\n",
    "#### 2. Train/Validation/Test performance with the optimal parameters\n",
    "These are the final metric results with the optimal parameters.\n",
    "\n",
    "| Split       | F1        | Precision | Recall |\n",
    "|-------------|-----------|-----------|--------|\n",
    "| Train  (Q1 to 3)       | 0.6903 | 0.7836 | 0.6537 |\n",
    "| Validation (Cross)     | \t0.6738 | 0.7617 | 0.6396 |\n",
    "| Test (Q4)      | 0.7576 |  0.7769 | 0.7422 |\n",
    "\n",
    "Confusion Matrix   \n",
    "Train:  \n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-xg-train.png?raw=true\" width=\"700\">\n",
    "\n",
    "Cross Validation Folds:  \n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-xg-q2.png?raw=true\" width=\"700\">\n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-xg-q3.png?raw=true\" width=\"700\">\n",
    "\n",
    "\n",
    "Final (Test Q4):  \n",
    "<img src=\"https://github.com/ericwu2024/w261/blob/main/p2-xg-final.png?raw=true\" width=\"700\">\n",
    "\n",
    "#### 3. Discussion\n",
    "\n",
    "##### 3.1. Impact of class weighting and boosting on detecting delayed flights\n",
    "\n",
    "Just like Logistic Regression and random forest, the class weighting preprocessed onto the model is also essesntial to preoduce more likely results of the prediction. The reason is prior to performing such strategy, XGBoost would also be biased to predict the majority class not_delayed class.\n",
    "\n",
    "With this weighting, however, the improvement does come with a some false positives that we can see in the confusion matrix, creating the trade off between recall and precision.\n",
    "\n",
    "With a depth of 6 instead of the shallower 4, the model is relatively deep to capture some trends in the data yet without fully being underfit to the occasional extremes or out of ordinary patterns of the dataset.\n",
    "\n",
    "##### 3.2. Trade-off between recall and precision\n",
    "\n",
    "Our XGBoost model shows the trade off at predicing the flight delays. Despite the F1 score indicating a relative balance between the precision and recall metric and our goal at obtaining the best model on the recall metric, the model at predicitng the false negatives on the test dataset is severely outperformed by the precision of the model. Granted that the F1-score metric indicates that there is a balance between the precision and recall metrics, the XGBoost model, per the hyperparameters as it currently stands, delivers well at capturng the true delays despite the possible holiday travel noise within Q4. (Note: Precision is not our goal for the parameter tuning)\n",
    "\n",
    "##### 3.3. Generalization to Q4 and limitations\n",
    "\n",
    "Based on the results presented above for the model, XGBoost generalizes well with just a small edge against the random forest model and well above our logistic regression model (when looking at the performance of the F1 Score metric as the balance - with the tuning target of the recall metric). This can be due to how we have regularization as part of the input parameters to minimize the scenario of overfitting the model. In fact, the delta between the metrics are about 10% (0.1) of one another for the model. This signifies that the model is relatively stable at making its flight delay classification predictions. \n",
    "\n",
    "However, the class imbalance persists. Even the class weighting, the flight outcomes are not truly predicted well per the dataset due to noise and seasonality similar to the discussions per our other models. (Like routes, unforeseeen events, etc.) \n",
    "\n",
    "Forthermore, computational constraints of the CPU per our cluster size (as mentioned in the pipelines section 6 above) hindered our search space efforts. Coupled with the limitations of time, the hyperparamter tuned model may not be the fully optimal model that we desire. Nevertheless, the results warrant a favorable exploration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a495d4c8-f1c6-4be6-9593-d66e2c3384f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This project addresses the challenge using a **supervised classification pipeline** to predict departure delays built on operational, weather, and temporal data. Our **hypothesis** is that models enriched with engineered features and regularized training procedures **can discriminate between delayed and non-delayed flights**. Our results support this: **PCA highlighted dominant variance components**, **Lasso regularization pruned low-signal predictors**, and **Logistic Regression** established a baseline. With **Random Forest and XGBoost**, we achieved **better recall** while balancing precision, signifying that powerful models can provide better prediction for flight delays.\n",
    "\n",
    "These findings demonstrates that **structured feature engineering and weighting** enhances generalization in imbalanced flight datasets. **Phase 3** will deepen the exploration through **graph-based connectivity metrics, class imbalance rebalancing, and hyperparameter optimization**. We plan to use a Multilayered Perceptron as an additional model. Collectively, these enhancements aim to produce a robust delay prediction system capable of reliable performance on unseen flight data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdd1bb40-26d1-4f76-b10e-0bb444dbf891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "006cadf4-5bce-4948-9820-fb0b2c971567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| **Section**                                   | **Notebook Link**                                                                                                                                                                                                                 |\n",
    "|-----------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data Load, Data Analysis and Data Quality Fixes| https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1739154845296342?o=4021782157704243#command/1739154845296343                                                   |\n",
    "|EDA - Correlation Analysis, PCA, Time Series Decomposition |https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/3056786081358273?o=4021782157704243#command/3056786081358274|\n",
    "| Lasso Regularization                         | https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1739154845297234?o=4021782157704243#command/7250714370592542$0                                                  |\n",
    "| Baseline Model - Logistic Regression         | https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1739154845297512?o=4021782157704243                                                                             |\n",
    "| XGBoost and Random Forest - Ensemble/Gradient Boosted Trees | https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957779848?o=4021782157704243#command/1792055957779849 |"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project Phase 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}